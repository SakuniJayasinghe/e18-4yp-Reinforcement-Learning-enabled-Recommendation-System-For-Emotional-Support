{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-26T08:23:54.288938Z",
     "start_time": "2024-06-26T08:23:54.264937Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import ast"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjson\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T08:23:17.142992Z",
     "start_time": "2024-06-26T08:23:17.112993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define Actor and Critic classes\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, action_dim)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        action_probs = torch.softmax(self.fc2(x), dim=-1)\n",
    "        return action_probs\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        value = self.fc2(x)\n",
    "        return value"
   ],
   "id": "2dcb5c4d90c341e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Define Actor and Critic classes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mActor\u001B[39;00m(\u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, state_dim, action_dim):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;28msuper\u001B[39m(Actor, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Safe eval function\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    df = df.fillna(method='ffill')\n",
    "    \n",
    "    # Identify numeric features\n",
    "    numeric_features = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # Normalize numeric features if they exist\n",
    "    if not numeric_features.empty:\n",
    "        scaler = StandardScaler()\n",
    "        df[numeric_features.columns] = scaler.fit_transform(numeric_features)\n",
    "    \n",
    "    # One-hot encode genres\n",
    "    df['genre'] = df['genre'].apply(safe_literal_eval)\n",
    "    df = df.explode('genre')\n",
    "    df = pd.get_dummies(df, columns=['genre'])\n",
    "    \n",
    "    # Ensure 'emotions' column is evaluated into lists\n",
    "    df['emotions'] = df['emotions'].apply(safe_literal_eval)\n",
    "    \n",
    "    return df"
   ],
   "id": "7e688f1a10b0b6d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the configuration\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract the values from the configuration\n",
    "user_id = config[\"user_id\"]\n",
    "ego_centric_dim = config[\"ego_centric_dim\"]\n",
    "user_preferences_dim = config[\"user_preferences_dim\"]\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "gamma = config[\"gamma\"]\n",
    "episodes = config[\"episodes\"]\n",
    "emotion_to_int = config[\"emotion_to_int\"]\n",
    "emotional_states = config[\"emotional_states\"]"
   ],
   "id": "7acea022a89b22e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the datasets from the uploaded files\n",
    "books_data = preprocess_data(pd.read_csv(r'D:\\Com Acca\\FYP\\e18-4yp-Reinforcement-Learning-enabled-Recommendation-System-For-Emotional-Support\\code\\Recommendation System\\Actor Critic Model\\book_filtered_data.csv'))\n",
    "movies_data = preprocess_data(pd.read_csv(r'D:\\Com Acca\\FYP\\e18-4yp-Reinforcement-Learning-enabled-Recommendation-System-For-Emotional-Support\\code\\Recommendation System\\Actor Critic Model\\movie_filtered_data.csv'))\n",
    "music_data = preprocess_data(pd.read_csv(r'D:\\Com Acca\\FYP\\e18-4yp-Reinforcement-Learning-enabled-Recommendation-System-For-Emotional-Support\\code\\Recommendation System\\Actor Critic Model\\music_filtered_data.csv'))"
   ],
   "id": "1d65e5758ff9527"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Encode emotions in the datasets\n",
    "def encode_emotions(df):\n",
    "    df['emotions'] = df['emotions'].apply(lambda x: [emotion_to_int[emotion] for emotion in x])\n",
    "    return df\n",
    "\n",
    "books_data = encode_emotions(books_data)\n",
    "music_data = encode_emotions(music_data)\n",
    "movies_data = encode_emotions(movies_data)"
   ],
   "id": "bbe5314feb3b7bb1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize state_dim and action_dim\n",
    "state_dim = len(emotional_states) + ego_centric_dim + user_preferences_dim\n",
    "action_dim = max(len(music_data), len(books_data), len(movies_data))\n",
    "\n",
    "# Load the models\n",
    "loaded_actor = Actor(state_dim, action_dim)\n",
    "loaded_critic = Critic(state_dim)\n",
    "\n",
    "loaded_actor.load_state_dict(torch.load('actor.pth'))\n",
    "loaded_critic.load_state_dict(torch.load('critic.pth'))\n",
    "\n",
    "loaded_actor.eval()\n",
    "loaded_critic.eval()"
   ],
   "id": "998aa47d733131f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class RecommenderEnv:\n",
    "    def __init__(self, user_id, music_data, books_data, movies_data, emotional_states):\n",
    "        self.user_id = user_id\n",
    "        self.music_data = music_data\n",
    "        self.books_data = books_data\n",
    "        self.movies_data = movies_data\n",
    "        self.emotional_states = emotional_states\n",
    "        self.state = None\n",
    "        self.data = {\n",
    "            'music': self.music_data,\n",
    "            'books': self.books_data,\n",
    "            'movies': self.movies_data\n",
    "        }\n",
    "        self.action_space = {\n",
    "            'music': len(self.music_data),\n",
    "            'books': len(self.books_data),\n",
    "            'movies': len(self.movies_data)\n",
    "        }\n",
    "\n",
    "    def reset(self, specified_emotional_state=None):\n",
    "        ego_centric_data = self.get_ego_centric_data()\n",
    "        user_preferences = self.get_user_preferences(self.user_id)\n",
    "        if specified_emotional_state is not None:\n",
    "            emotional_state = specified_emotional_state\n",
    "        else:\n",
    "            emotional_state = np.zeros(len(self.emotional_states))\n",
    "            emotional_state[np.random.choice(len(self.emotional_states))] = 1\n",
    "        self.state = np.concatenate((emotional_state, ego_centric_data, user_preferences)).astype(np.float32)\n",
    "        self.current_emotional_state = np.argmax(emotional_state)  # Store the current emotional state as an integer\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action, item_type, user_feedback=None):\n",
    "        action = action % self.action_space[item_type]  # Ensure the action is within the valid range\n",
    "        next_state, reward, done = self._simulate_interaction(action, item_type, user_feedback)\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def _simulate_interaction(self, action, item_type, user_feedback):\n",
    "        next_state = self.reset()  # Reset to get the next state with new ego-centric data and user preferences\n",
    "        \n",
    "        if user_feedback is not None:\n",
    "            reward = 1 if user_feedback == 'like' else -1\n",
    "        else:\n",
    "            reward = np.random.rand()\n",
    "        \n",
    "        done = np.random.rand() < 0.1\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def get_recommendation(self, item_type):\n",
    "        # Filter the activities based on the current emotional state\n",
    "        valid_actions = self.data[item_type][self.data[item_type]['emotions'].apply(lambda x: self.current_emotional_state in x)].index\n",
    "        if len(valid_actions) == 0:\n",
    "            return None\n",
    "        action = np.random.choice(valid_actions)\n",
    "        return action\n",
    "\n",
    "    @staticmethod\n",
    "    def get_ego_centric_data():\n",
    "        # This function should return a feature vector representing the user's environment\n",
    "        # For simplicity, we return a random vector here\n",
    "        return np.random.rand(5).astype(np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_user_preferences(user_id):\n",
    "        # This function should return a feature vector representing the user's preferences\n",
    "        # For simplicity, we return a random vector here\n",
    "        return np.random.rand(5).astype(np.float32)"
   ],
   "id": "91327c396e9c07f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Re-initialize the environment\n",
    "loaded_env = RecommenderEnv(user_id=user_id, music_data=music_data, books_data=books_data, movies_data=movies_data, emotional_states=emotional_states)\n"
   ],
   "id": "d7c0de807796fbdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_user_emotional_state(emotional_states):\n",
    "    print(\"Please enter your current emotional state:\")\n",
    "    for i, emotion in enumerate(emotional_states):\n",
    "        print(f\"{i}: {emotion}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            mood = int(input(\"Enter the number corresponding to your current emotional state: \").strip())\n",
    "            if 0 <= mood < len(emotional_states):\n",
    "                emotional_state = np.zeros(len(emotional_states))\n",
    "                emotional_state[mood] = 1\n",
    "                return emotional_state\n",
    "            else:\n",
    "                print(f\"Invalid input. Please enter a number between 0 and {len(emotional_states) - 1}.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid number.\")\n"
   ],
   "id": "6a2c5282507e156e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_user_feedback():\n",
    "    while True:\n",
    "        feedback = input(\"Did you like the recommendation? (yes/no): \").strip().lower()\n",
    "        if feedback in ['yes', 'no']:\n",
    "            return 'like' if feedback == 'yes' else 'dislike'\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'yes' or 'no'.\")\n"
   ],
   "id": "891677dc6ae9c4bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def interactive_recommendation_system(env, actor, emotional_states):\n",
    "    while True:\n",
    "        user_emotional_state = get_user_emotional_state(emotional_states)\n",
    "        state = env.reset(specified_emotional_state=user_emotional_state)\n",
    "        state = torch.FloatTensor(state)\n",
    "\n",
    "        while True:\n",
    "            recommendations = {}\n",
    "            feedbacks = {}\n",
    "\n",
    "            for item_type in ['music', 'books', 'movies']:\n",
    "                action = env.get_recommendation(item_type)\n",
    "                if action is None:\n",
    "                    print(f\"No valid recommendations available for {item_type}.\")\n",
    "                    continue\n",
    "\n",
    "                recommendation = env.data[item_type].iloc[action]\n",
    "                recommendations[item_type] = recommendation\n",
    "                print(f\"Recommended {item_type[:-1]}: {recommendation['name']}\")\n",
    "\n",
    "                feedbacks[item_type] = get_user_feedback()\n",
    "\n",
    "            for item_type, feedback in feedbacks.items():\n",
    "                if item_type in recommendations:\n",
    "                    next_state, reward, done = env.step(recommendations[item_type].name, item_type, feedback)\n",
    "                    next_state = torch.FloatTensor(next_state)\n",
    "                    state = next_state\n",
    "\n",
    "            another_recommendation = input(\"Would you like another set of recommendations based on the same emotion? (yes/no): \").strip().lower()\n",
    "            if another_recommendation != 'yes':\n",
    "                break\n",
    "        \n",
    "        another_emotion = input(\"Would you like to provide a new emotional state for new recommendations? (yes/no): \").strip().lower()\n",
    "        if another_emotion != 'yes':\n",
    "            break\n",
    "\n"
   ],
   "id": "21e420fe4ce6803a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example usage with the loaded models and environment\n",
    "interactive_recommendation_system(loaded_env, loaded_actor, emotional_states)"
   ],
   "id": "582204507036697a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
